{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing My Spotify Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Payton Burks  \n",
    "CPSC 222, Fall 2020  \n",
    "17 December 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain\n",
    "\n",
    "This project deals with music and (my) listening statistics. I have loved listening to music since I was a kid, so I thought analyzing my listening habits would be insightful. Though I have no intention of ever creating music, it has played an important part of my development and will likely continue to do so. Hopefully I am able to glean some insights into what I listen to on a particular day, what artists I like the most, and how different my music taste is apart from others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The raw data is imported as json files with 4 categories:\n",
    "* endTime = date and time the song finished (formatted 'year-month-day hour:minute')\n",
    "* artistName = artist\n",
    "* trackName = song\n",
    "* msPlayed = milliseconds played\n",
    "\n",
    "I will be appending...\n",
    "* day = day of the week\n",
    "* skipped? = if the song was skipped (listened to for $\\leq$ 30s)\n",
    "* top100artist? = if the artist was in my top 100 most played artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis Testing\n",
    "\n",
    "I will be testing the following hypotheses:\n",
    "* The average length of songs I listen to is shorter than the average length of hit songs worldwide \n",
    "* I listen to more music (per day, on average) on weekends than weekdays.\n",
    "* I skip songs by my top 100 artists more often than songs by those who aren't on my top 100 list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stockholders\n",
    "\n",
    "Personally, I am a huge stakeholder in these results; the information is fascinating to me. Additionally, due to the fact I am creating a model to see what makes my skips happen more often, these results could be huge to artists in the music industry. If they can get information on which of their songs were skipped more often, they may be able to turn a higher profit on their next project (assuming these results are reproduced with different streaming data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "I will be using the \"skipped?\" category as my classification element. I will be trying to see if I can classify whether or not I skipped a song based on the other characteristics (not including msPlayed, as that directly correlates to skipping the song)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Description\n",
    "\n",
    "As previously noted, the raw data comes in as json files. In order to more easily manipulate my data, I loaded each one into a DataFrame and then merged them into one gigantic DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utils\n",
    "\n",
    "#load in data\n",
    "data0 = utils.load_data(\"StreamingHistoryJsonFiles/StreamingHistory0.json\")\n",
    "data1 = utils.load_data(\"StreamingHistoryJsonFiles/StreamingHistory1.json\")\n",
    "data2 = utils.load_data(\"StreamingHistoryJsonFiles/StreamingHistory2.json\")\n",
    "data3 = utils.load_data(\"StreamingHistoryJsonFiles/StreamingHistory3.json\")\n",
    "data4 = utils.load_data(\"StreamingHistoryJsonFiles/StreamingHistory4.json\")\n",
    "data5 = utils.load_data(\"StreamingHistoryJsonFiles/StreamingHistory5.json\")\n",
    "\n",
    "#join all data into spot_df\n",
    "spot_df = pd.concat([data0, data1, data2, data3, data4, data5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder, there are four initial attributes to the data *(endTime*, *artistName*, *artist*, *trackName*, *msPlayed*). In-depth descriptions can be found above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "#### Data Cleaning\n",
    "\n",
    "The only issue I had with computationally with the data was the '\\\\$' character found in artists such as Joey Bada\\\\$\\\\$ and A\\\\$AP Rocky, among others. This was causing problems, so I replaced '\\\\$' with 'S'.\n",
    "\n",
    "Next, I had two tasks remaining. I had to replace \"Unknown Artist\" with \"Playboi Carti\" (Spotify was picking up my local files - which are all Playboi Carti song leaks - as \"Unknown Artist\") and remove the podcasts that I listened to. Finally, I could move the clean data to a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean data   \n",
    "utils.clean_spot_df(spot_df)\n",
    "utils.rm_pod(spot_df)\n",
    "\n",
    "spot_df = spot_df.reset_index(drop=True)\n",
    "\n",
    "#data to csv\n",
    "spot_df.to_csv(\"cleanspotifydata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Appending other data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the preparation, I would be appending three new attributes (*day, skipped?, top100artist?*). Again, more in-depth descriptions of these attributes are found above. In order to find my top 100 artists for the respective attribute, I would have to compute a new dataframe which was composed of two columns, artist and hoursListened.\n",
    " \n",
    "While preparing these attributes, I was also able to compute a few statistics and find out more information about the data. These are printed beneath some of the code that allowed me to create the new attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *day*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dates from data\n",
    "raw_dates = utils.get_date_list(spot_df)\n",
    "\n",
    "#combine dates with findDay\n",
    "day_of_week = []\n",
    "for item in raw_dates:\n",
    "    newEntry = utils.findDay(item)\n",
    "    day_of_week.append(newEntry)\n",
    "\n",
    "#append day_of_week to spot_df\n",
    "spot_df[\"day\"] = day_of_week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *skipped?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs skipped: 11952\n",
      "Percent of songs skipped: 21.02 %\n"
     ]
    }
   ],
   "source": [
    "#newvars\n",
    "skipped = []\n",
    "timeListen = spot_df[\"msPlayed\"].copy()\n",
    "numSkips = 0\n",
    "totSongs = 0\n",
    "\n",
    "#loop through data\n",
    "for item in timeListen:\n",
    "    secListened = item/1000\n",
    "    if secListened < 30:\n",
    "        skipped.append('y')\n",
    "        numSkips += 1\n",
    "        totSongs += 1\n",
    "    else:\n",
    "        skipped.append('n')\n",
    "        totSongs += 1\n",
    "        \n",
    "#append data\n",
    "spot_df[\"skipped?\"] = skipped\n",
    "\n",
    "print(\"Number of songs skipped:\", numSkips)\n",
    "print(\"Percent of songs skipped:\", round((numSkips/totSongs),4)*100, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *top100artist?*\n",
    "\n",
    "###### **Must first create new DataFrame, artist X hours listened*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total hours listened to: 2178\n",
      "Total days: 91\n"
     ]
    }
   ],
   "source": [
    "#new vars\n",
    "bigtotal = 0\n",
    "#vars for new DF\n",
    "totalHours_perArtist = []\n",
    "artist_perArtist = []\n",
    "#grouping by artist\n",
    "group_by_artist_df = spot_df.groupby(\"artistName\")\n",
    "\n",
    "for artist, group_df in group_by_artist_df:\n",
    "    msplayed_ser = group_df[\"msPlayed\"].copy()\n",
    "    totalms = msplayed_ser.sum()\n",
    "    totalhours = totalms/1000/60/60\n",
    "    bigtotal += totalhours\n",
    "    \n",
    "    #data for new df for hours x artist\n",
    "    totalHours_perArtist.append(round(totalhours, 2))\n",
    "    artist_perArtist.append(artist)\n",
    "    \n",
    "artist_x_hours_df = utils.create_artist_x_hours_df(artist_perArtist, totalHours_perArtist)\n",
    "\n",
    "print(\"Total hours listened to:\", round(bigtotal))\n",
    "print(\"Total days:\", round(bigtotal/24))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Actually creating *top100artist?* attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new vars\n",
    "top100YorN = []\n",
    "artist_data = spot_df[\"artistName\"].copy()\n",
    "artist_data = artist_data.to_list()\n",
    "top100 = artist_x_hours_df.iloc[0:101][\"Artist\"].copy()\n",
    "\n",
    "#loop through data\n",
    "for artist in artist_data:\n",
    "    artistIsIn = False\n",
    "    for item in top100:\n",
    "        if item == artist:\n",
    "            artistIsIn = True\n",
    "            break\n",
    "    if artistIsIn == True:\n",
    "        top100YorN.append('y')\n",
    "    else:\n",
    "        top100YorN.append('n')\n",
    "#append        \n",
    "spot_df[\"top100Artist?\"] = top100YorN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Convert new, fuller DataFrame to a new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_df.to_csv('finalspotifydata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
